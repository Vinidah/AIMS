summary(iris)
plot(iris)
install.packages('packman')
install.packages("packman")
library('datasets')
head('irish')
library('datasets')
head(iris3)
head(iris)
head(iris)
irish
tail(irish)
tail(iris)
plot(iris$Species)
plot(iris$Sepal.Length)
plot(iris$Petal.Length, iris$Petal.Width, col="#cc0000",
xlab = "Petal Length",
ylab = "Petal Width")
plot(iris$Petal.Length, iris$Petal.Width, col="#ccab00",
xlab = "Petal Length",
ylab = "Petal Width")
plot(iris$Petal.Length, iris$Petal.Width, col="#ccab00",
xlab = "Petal Length",
main = "Distribution of dataset",
ylab = "Petal Width")
plot(iris$Petal.Length, iris$Petal.Width, col="#ccab00",
xlab = "Petal Length",
pch = 18,
main = "Distribution of dataset",
ylab = "Petal Width")
plot(iris$Petal.Length, iris$Petal.Width, col="#ccab00",
xlab = "Petal Length",
pch = 17,
main = "Distribution of dataset",
ylab = "Petal Width")
plot(iris$Petal.Length, iris$Petal.Width, col="#ccab00",
xlab = "Petal Length",
pch = 19,
main = "Distribution of dataset",
ylab = "Petal Width")
plot(iris$Petal.Length, iris$Petal.Width, col="#ccab87",
xlab = "Petal Length",
pch = 19,
main = "Distribution of dataset",
ylab = "Petal Width")
plot(iris$Petal.Length, iris$Petal.Width, col="#ccab87",
xlab = "Petal Length",
pch = 19,
main = "Distribution of dataset",
ylab = "Petal Width")
plot(iris$Petal.Length, iris$Petal.Width, col="#ccab87",
xlab = "Petal Length",
pch = 19,
main = "Distribution of dataset",
ylab = "Petal Width")
plot(iris$Petal.Length, iris$Petal.Width, col="#ccab00",
xlab = "Petal Length",
pch = 19,
main = "Distribution of dataset",
ylab = "Petal Width")
plot(iris$Petal.Length, iris$Petal.Width, col="#cc0000",
xlab = "Petal Length",
pch = 19,
main = "Distribution of dataset",
ylab = "Petal Width")
plot(exp,-100,100)
plot(dnorm,-100,100)
plot(dnorm,-100,100)
plot(exp,-100,100)
plot(exp,2,10)
exp(6)
library(datasets)
mtcars?
?mtcars
plot(cars)
plot(mtcars)
head(mtcars)
barplot(table((mtcars$cyl)))
setwd("~/Desktop/AIMS/Lectures/Review Phase/Block 5/BDML/Assignments/002")
library(class)
library(MASS)
library(kernlab)
library(class)
library(MASS)
library(kernlab)
library(mlbench)
library(reshape2)
library(ROCR)
library(ggplot2)
data(PimaIndiansDiabetes)        # load the data
xy <- PimaIndiansDiabetes        # Store data in xy frame
help(PimaIndiansDiabetes)
head(xy)
tail(xy)
str(xy)
library(xtable)
xtable(head(xy))
n   <- nrow(xy)       # Sample size
p   <- ncol(xy) - 1   # Dimensionality of the input space
pos <- p+1            # Position of the response
x   <- xy[,-pos]      # Data matrix: n x p matrix
y   <- xy[, pos]      # Response vector
n; p
library(corrplot)
corrplot(cor(x))
plot(x, col=as.numeric(y)+2)
par(mfrow=c(3,3))
for(j in 1:p)
{
boxplot(x[,j]~y, col=2:3, ylab=colnames(x)[j], xlab='diabetic')
}
boxplot(x)
barplot(prop.table(table(y)), col=2:3, xlab='diabetic')
set.seed (19671210)   # Set seed for random number generation to be reproducible
epsilon <- 1/3               # Proportion of observations in the test set
nte     <- round(n*epsilon)  # Number of observations in the test set
ntr     <- n - nte
id.tr   <- sample(sample(sample(n)))[1:ntr]   # For a sample of ntr indices from {1,2,..,n}
#id .tr <- sample(1:n, ntr, replace=F)        # Another way to draw from {1,2,..n}
id.te   <- setdiff(1:n, id.tr)
k        <- 9
y.te     <- y[id.te]                                 # True responses in test set
y.te.hat <- knn(x[id.tr,], x[id.te,], y[id.tr], k=k) # Predicted responses in test set
conf.mat.te <- table(y.te, y.te.hat)
conf.mat.te
k        <- 1
y.tr     <- y[id.tr]                                 # True responses in test set
y.tr.hat <- knn(x[id.tr,], x[id.tr,], y[id.tr], k=k) # Predicted responses in test set
conf.mat.tr <- table(y.tr, y.tr.hat)
conf.mat.tr
ind.err.te <- ifelse(y.te!=y.te.hat,1,0)      # Random variable tracking error. Indicator
ind.err.te
id.err     <- which(y.te!=y.te.hat)           # Which obs are misclassified
id.err
conf.mat.te <- table(y.te, y.te.hat)
conf.mat.te
pcc.te <- sum(diag(conf.mat.te))/nte
# pcc.te <- 1-mean(ind.err.te)        # Another way from ind.err.te
# pcc.te <- 1-length(id.err.te)/nte   # Yet another way fr
pcc.te
err.te <- 1-pcc.te                    # Complement of accurary
err.te
library(ROCR)
y.roc <- ifelse(y=='Yes',1,0)
kNN.mod <- class::knn(x[id.tr,], x[id.tr,], y.roc[id.tr], k=3, prob=TRUE)
prob    <- attr(kNN.mod, 'prob')
prob    <- 2*ifelse(kNN.mod == "0", 1-prob, prob) - 1
pred.knn <- prediction(prob, y.roc[id.tr])
library(ROCR)
y.roc <- ifelse(y=='Yes',1,0)
kNN.mod <- class::knn(x[id.tr,], x[id.tr,], y.roc[id.tr], k=1, prob=TRUE)
prob    <- attr(kNN.mod, 'prob')
prob    <- 2*ifelse(kNN.mod == "0", 1-prob, prob) - 1
pred.1NN <- prediction(prob, y.roc[id.tr])
xtr <- x #x[id.tr,]          # Using the only the training for validation
ytr <- y #y[id.tr]           # We could use the entire sample but that's greedy
vK <- seq(1, 25, by=1)    # Grid of values of k
nK <- length(vK)          # Number of values of k considered
cv.error <-numeric(nK)    # Vector of cross validation errors for each k
nc <- nrow(xtr)           # Number of observations used for cross validation
c   <- 10                 # Number of folds. We are doing c-fold cross validation
S   <- sample(sample(nc)) # We randomly shuffle the data before starting CV
m   <- ceiling(nc/c)      # Maximum Number of observations in each fold
held.out.set <- matrix(0, nrow=c, ncol=m) # Table used to track the evolution
for(ic in 1:(c-1))
{
held.out.set[ic,] <- S[((ic-1)*m + 1):(ic*m)]
}
held.out.set[c, 1:(nc-(c-1)*m)] <- S[((c-1)*m + 1):nc]  # Handling last chunk just in case n!=mc
for(j in 1:nK)
{
for(i in 1:c)
{
out <-  held.out.set[i,]
yhatc<- knn(xtr[-out,], xtr[out,],ytr[-out],  k=vK[j])
cv.error[j]<-cv.error[j] + (length(out)-sum(diag(table(ytr[out],yhatc))))/length(out)
}
cv.error[j]<-cv.error[j]/c
}
plot(vK, cv.error, xlab='k', ylab=expression(CV[Error](k)),
main='Choice of k in k Nearest Neighbor by m-fold Cross Validation')
lines(vK, cv.error, type='c')
cv <- data.frame(vK, cv.error)
colnames(cv) <- c('k','error')
ggplot(cv, aes(k,error))+geom_point()+geom_line()+
labs(x='k=size of neighborhood', y=expression(CV[Error](k)))
library(class)
library(MASS)
library(kernlab)
library(mlbench)
library(reshape2)
library(ROCR)
library(ggplot2)
library(ada)
setwd("~/Desktop/AIMS/Lectures/Review Phase/Block 5/BDML/Lectures/2021/codebase")
library(class)
library(MASS)
library(kernlab)
library(mlbench)
library(reshape2)
library(ROCR)
library(ggplot2)
library(ada)
library(adabag)
library(ipred)
library(survival)
library(rchallenge)
library(PerformanceAnalytics)
library(knitr)
library(acepack)
library(caret)
library(HSAUR2)
library(corrplot)
xy <- read.csv('doughnuts-easy.csv')
xy <- read.csv('doughnuts.csv')
xy <- read.csv('four-corners-data-1.csv')
xy <- read.csv('simple-2d-for-knn-2.csv'); colnames(xy)[2:3]<-c('X1','X2')
xy <- read.csv('simple-2d-for-knn.csv'); colnames(xy)[2:3]<-c('X1','X2')
xy <- read.csv('banana-shaped-data-1.csv')
head(xy)
tail(xy)
xy[sample(nrow(xy))[1:10],]
which(is.na(xy))
library(xtable)
xtable(head(xy))
str(xy)
n   <- nrow(xy)       # Sample size
p   <- ncol(xy) - 1   # Dimensionality of the input space
pos <- 1+p              # Position of the response
x   <- xy[,-pos]      # Data matrix: n x p matrix
y   <- as.factor(xy[, pos])      # Response vector
n; p
library(corrplot)
corr.x <- cor(xy[,-pos])
corrplot(corr.x)
plot(xy[,-pos], col=xy[,pos]+2)
library(KernSmooth)
x <- xy[,-pos]
dens.est <- bkde2D(x, bandwidth = sapply(x,dpik))
plot(x, xlab = expression(X[1]), ylab=expression(X[2]))
contour(x = dens.est$x1, y = dens.est$x2, z = dens.est$fhat, add = TRUE)
logistic.xy <- glm(as.factor(y)~., data=xy, family=binomial(link='logit'))
summary(logistic.xy)
aic.xy <- step(logistic.xy, scope=~., direction='both', k=2, trace=0)
summary(aic.xy)
bic.xy <- step(logistic.xy, scope=~., direction='both', k=log(n), trace=0)
summary(bic.xy)
par(mfrow=c(1,2))
hist(xy$X1, prob=T)
lines(density(xy$X1), lwd=2, col='red')
boxplot(xy$X1)
par(mfrow=c(1,2))
boxplot(X1~y, data=xy, col=2:3)
boxplot(X2~y, data=xy, col=2:3)
log.acc <- glm(as.factor(y)~X1, data=xy, family=binomial(link='logit'))
summary(log.acc)
set.seed (19671210)          # Set seed for random number generation to be reproducible
epsilon <- 1/3               # Proportion of observations in the test set
nte     <- round(n*epsilon)  # Number of observations in the test set
ntr     <- n - nte
id.tr   <- sample(sample(sample(n)))[1:ntr]   # For a sample of ntr indices from {1,2,..,n}
#id .tr <- sample(1:n, ntr, replace=F)        # Another way to draw from {1,2,..n}
id.te   <- setdiff(1:n, id.tr)
stratified.holdout <- function(y, ptr)
{
n              <- length(y)
labels         <- unique(y)       # Obtain classifiers
id.tr <- id.te <- NULL
# Loop once for each unique label value
y <- sample(sample(sample(y)))
for(j in 1:length(labels))
{
sj    <- which(y==labels[j])  # Grab all rows of label type j
nj    <- length(sj)           # Count of label j rows to calc proportion below
id.tr <- c(id.tr, (sample(sample(sample(sj))))[1:round(nj*ptr)])
}                               # Concatenates each label type together 1 by 1
id.te  <- (1:n) [-id.tr]          # Obtain and Shuffle test indices to randomize
return(list(idx1=id.tr,idx2=id.te))
}
hold <- stratified.holdout(as.factor(xy[,pos]), 1-epsilon)
id.tr <- hold$idx1
id.te <- hold$idx2
ntr   <- length(id.tr)
nte   <- length(id.te)
library(class)
k        <- 9
y.te     <- y[id.te]                                 # True responses in test set
y.te.hat <- knn(x[id.tr,], x[id.te,], y[id.tr], k=k) # Predicted responses in test set
conf.mat.te <- table(y.te, y.te.hat)
conf.mat.te
k        <- 1
y.tr     <- y[id.tr]                                 # True responses in test set
y.tr.hat <- knn(x[id.tr,], x[id.tr,], y[id.tr], k=k) # Predicted responses in test set
conf.mat.tr <- table(y.tr, y.tr.hat)
conf.mat.tr
ind.err.te <- ifelse(y.te!=y.te.hat,1,0)      # Random variable tracking error. Indicator
ind.err.te
# Identification of misclassified cases
id.err     <- which(y.te!=y.te.hat)           # Which obs are misclassified
id.err
# Confusion matrix
conf.mat.te <- table(y.te, y.te.hat)
conf.mat.te
pcc.te <- sum(diag(conf.mat.te))/nte
# pcc.te <- 1-mean(ind.err.te)        # Another way from ind.err.te
# pcc.te <- 1-length(id.err.te)/nte   # Yet another way fr
pcc.te
# Test Error
err.te <- 1-pcc.te                    # Complement of accurary
err.te
y.roc   <- as.factor(y)
kNN.mod <- class::knn(x[id.tr,], x[id.tr,], y.roc[id.tr], k=3, prob=TRUE)
prob    <- attr(kNN.mod, 'prob')
prob    <- 2*ifelse(kNN.mod == "0", 1-prob, prob) - 1
pred.knn <- prediction(prob, y.roc[id.tr])
perf.knn <- performance(pred.knn, measure='tpr', x.measure='fpr')
plot(perf.knn, col=2, lwd= 2, lty=2, main=paste('ROC curve for kNN with k=3'))
abline(a=0,b=1)
library(ROCR)
y.roc   <- as.factor(y)
kNN.mod <- class::knn(x[id.tr,], x[id.tr,], y.roc[id.tr], k=1, prob=TRUE)
prob    <- attr(kNN.mod, 'prob')
prob    <- 2*ifelse(kNN.mod == "0", 1-prob, prob) - 1
pred.1NN <- prediction(prob, y.roc[id.tr])
perf.1NN <- performance(pred.1NN, measure='tpr', x.measure='fpr')
kNN.mod <- class::knn(x[id.tr,], x[id.tr,], y.roc[id.tr], k=13, prob=TRUE)
prob    <- attr(kNN.mod, 'prob')
prob    <- 2*ifelse(kNN.mod == "0", 1-prob, prob) - 1
pred.13NN <- prediction(prob, y.roc[id.tr])
perf.13NN <- performance(pred.13NN, measure='tpr', x.measure='fpr')
kNN.mod <- class::knn(x[id.tr,], x[id.tr,], y.roc[id.tr], k=28, prob=TRUE)
prob    <- attr(kNN.mod, 'prob')
prob    <- 2*ifelse(kNN.mod == "0", 1-prob, prob) - 1
pred.28NN <- prediction(prob, y.roc[id.tr])
perf.28NN <- performance(pred.28NN, measure='tpr', x.measure='fpr')
plot(perf.1NN, col=2, lwd= 2, lty=2, main=paste('Comparative ROC curves in Training'))
plot(perf.13NN, col=3, lwd= 2, lty=3, add=TRUE)
plot(perf.28NN, col=4, lwd= 2, lty=4, add=TRUE)
abline(a=0,b=1)
legend('bottomright', inset=0.05, c('1NN','13NN', '28NN'),  col=2:4, lty=2:4)
library(ROCR)
y.roc   <- as.factor(y)
kNN.mod <- class::knn(x[id.tr,], x[id.te,], y.roc[id.tr], k=1, prob=TRUE)
prob    <- attr(kNN.mod, 'prob')
prob    <- 2*ifelse(kNN.mod == "0", 1-prob, prob) - 1
pred.1NN <- prediction(prob, y.roc[id.te])
perf.1NN <- performance(pred.1NN, measure='tpr', x.measure='fpr')
kNN.mod <- class::knn(x[id.tr,], x[id.te,], y.roc[id.tr], k=13, prob=TRUE)
prob    <- attr(kNN.mod, 'prob')
prob    <- 2*ifelse(kNN.mod == "0", 1-prob, prob) - 1
pred.13NN <- prediction(prob, y.roc[id.te])
perf.13NN <- performance(pred.13NN, measure='tpr', x.measure='fpr')
kNN.mod <- class::knn(x[id.tr,], x[id.te,], y.roc[id.tr], k=28, prob=TRUE)
prob    <- attr(kNN.mod, 'prob')
prob    <- 2*ifelse(kNN.mod == "0", 1-prob, prob) - 1
pred.28NN <- prediction(prob, y.roc[id.te])
perf.28NN <- performance(pred.28NN, measure='tpr', x.measure='fpr')
plot(perf.1NN, col=2, lwd= 2, lty=2, main=paste('Comparison of Predictive ROC curves'))
plot(perf.13NN, col=3, lwd= 2, lty=3, add=TRUE)
plot(perf.28NN, col=4, lwd= 2, lty=4, add=TRUE)
abline(a=0,b=1)
legend('bottomright', inset=0.05, c('1NN','13NN', '28NN'),  col=2:4, lty=2:4)
head(mnist)
library(MASS)
library(class)
##Exercise 3
library(mnist)
mnist <- download_mnist()
head(mnist)
mnist[mnist$Label == 5]
mnist[mnist$Label == "7" ]
filter(mnist, mnist$Label == "5")
mnis[mnist$Label == "5",]
mnist[mnist$Label == "5",]
mnist[mnist$Label == "5","7"]
install.packages("yardstick")
y.roc   <- as.factor(y)
y.roc
library(devtools)
install_github("vqv/ggbiplot")
hold <- stratified.holdout(as.factor(xy[,pos]), 1-epsilon)
id.tr <- hold$idx1
id.te <- hold$idx2
ntr   <- length(id.tr)
nte   <- length(id.te)
hold
n   <- nrow(xy)       # Sample size
p   <- ncol(xy) - 1   # Dimensionality of the input space
pos <- 1+p              # Position of the response
x   <- xy[,-pos]      # Data matrix: n x p matrix
y   <- as.factor(xy[, pos])      # Response vector
n; p
p
xy
p
set.seed (19671210)          # Set seed for random number generation to be reproducible
epsilon <- 1/3               # Proportion of observations in the test set
nte     <- round(n*epsilon)  # Number of observations in the test set
ntr     <- n - nte
#k.opt.cv <- 28
R <- 100   # Number of replications
test.err <- numeric(R)
for(r in 1:R)
{
# Split the data
id.tr   <- sample(sample(sample(n)))[1:ntr]                   # For a sample of ntr indices from {1,2,..,n}
id.te   <- setdiff(1:n, id.tr)
y.te         <- y[id.te]                                        # True responses in test set
y.te.hat     <- knn(x[id.tr,], x[id.te,], y[id.tr], k=k.opt.cv) # Predicted responses in test set
ind.err.te   <- ifelse(y.te!=y.te.hat,1,0)                      # Random variable tracking error. Indicator
test.err[r]  <- mean(ind.err.te)
}
k.opt.cv <- max(which(cv.error==min(cv.error)))
set.seed (19671210)          # Set seed for random number generation to be reproducible
epsilon <- 1/3               # Proportion of observations in the test set
nte     <- round(n*epsilon)  # Number of observations in the test set
ntr     <- n - nte
#k.opt.cv <- 28
R <- 100   # Number of replications
test.err <- numeric(R)
for(r in 1:R)
{
# Split the data
id.tr   <- sample(sample(sample(n)))[1:ntr]                   # For a sample of ntr indices from {1,2,..,n}
id.te   <- setdiff(1:n, id.tr)
y.te         <- y[id.te]                                        # True responses in test set
y.te.hat     <- knn(x[id.tr,], x[id.te,], y[id.tr], k=k.opt.cv) # Predicted responses in test set
ind.err.te   <- ifelse(y.te!=y.te.hat,1,0)                      # Random variable tracking error. Indicator
test.err[r]  <- mean(ind.err.te)
}
test <- data.frame(test.err)
colnames(test) <- c('error')
ggplot(test, aes(x='', y=error))+geom_boxplot()+
labs(x='Method', y=expression(hat(R)[te](kNN)))
library(PIMA
)
Pima.tr
head(Pima.tr)
head(Pima.tr[,-8])
head(Pima.tr[,-7])
head(Pima.tr[,-10])
dim(Pima.tr[,-10])
dim(Pima.tr[,-8])
head(Pima.tr[,-8])
head(Pima.tr[,-1])
str(Pima.tr)
set.seed (19671210)          # Set seed for random number generation to be reproducible
epsilon <- 1/3               # Proportion of observations in the test set
nte     <- round(n*epsilon)  # Number of observations in the test set
ntr     <- n - nte
R <- 100   # Number of replications
test.err <- matrix(0, nrow=R, ncol=5)
for(r in 1:R)
{
# Split the data
id.tr   <- sample(sample(sample(n)))[1:ntr]                   # For a sample of ntr indices from {1,2,..,n}
id.te   <- setdiff(1:n, id.tr)
y.te         <- y[id.te]                                        # True responses in test set
# First machine: 1NN
y.te.hat     <- knn(x[id.tr,], x[id.te,], y[id.tr], k=1)        # Predicted responses in test set
ind.err.te   <- ifelse(y.te!=y.te.hat,1,0)                      # Random variable tracking error. Indicator
test.err[r,1]  <- mean(ind.err.te)
# Second machine: Our optimal NN found earlier with k=k.opt.cv
y.te.hat     <- knn(x[id.tr,], x[id.te,], y[id.tr], k=k.opt.cv) # Predicted responses in test set
ind.err.te   <- ifelse(y.te!=y.te.hat,1,0)                      # Random variable tracking error. Indicator
test.err[r,2]  <- mean(ind.err.te)
# Third machine: k=round(sqrt(n))
y.te.hat     <- knn(x[id.tr,], x[id.te,], y[id.tr], k=round(sqrt(n)))       # Predicted responses in test set
ind.err.te   <- ifelse(y.te!=y.te.hat,1,0)                      # Random variable tracking error. Indicator
test.err[r,3]  <- mean(ind.err.te)
# Fourth machine: k=round(log(n))
y.te.hat     <- knn(x[id.tr,], x[id.te,], y[id.tr], k=round(log(n)))       # Predicted responses in test set
ind.err.te   <- ifelse(y.te!=y.te.hat,1,0)                      # Random variable tracking error. Indicator
test.err[r,4]  <- mean(ind.err.te)
# Fourth machine: k=log(n)
y.te.hat     <- knn(x[id.tr,], x[id.te,], y[id.tr], k=n)       # Predicted responses in test set
ind.err.te   <- ifelse(y.te!=y.te.hat,1,0)                      # Random variable tracking error. Indicator
test.err[r,5]  <- mean(ind.err.te)
}
library(class)
library(MASS)
library(kernlab)
library(mlbench)
library(reshape2)
library(ROCR)
library(ggplot2)
data(PimaIndiansDiabetes)        # load the data
xy <- PimaIndiansDiabetes        # Store data in xy frame
help(PimaIndiansDiabetes)
head(xy)
tail(xy)
str(xy)
library(xtable)
xtable(head(xy))
install_github('sinhrks/ggfortify')
devtools::install_github('IRkernel/repr')
setwd("~/Desktop/AIMS/Lectures/Review Phase/Block 5/BDML/Assignments/002")
library(class)
library(ROCR)
library(ggplot2)
library(caret)
library(yardstick)
library(corrplot)
library(xtable)
library(ggfortify)
library(devtools)
set.seed (19671210)
library(mnist)
mnist <- download_mnist()
n <- nrow(mnist)
p <- ncol(mnist) - 1
pos <- p + 1
